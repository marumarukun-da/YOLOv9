#!/usr/bin/env python3
"""
YOLOv9 ONNX Export Script

Export YOLOv9 models to ONNX format with or without NMS.
Supports flexible configuration via command-line arguments.
"""

import argparse
from pathlib import Path

import torch
import torch.nn as nn
from hydra import compose, initialize

from yolo.model.yolo import create_model
from yolo.utils.bounding_box_utils import create_converter
from yolo.utils.model_utils import PostProcess


class FullYoloExport(nn.Module):
    """YOLO Export with NMS included"""

    def __init__(self, model, cfg):
        super().__init__()
        self.model = model.eval()
        self.converter = create_converter(
            cfg.model.name,
            model,
            cfg.model.anchor,
            cfg.task.data.image_size,
            device="cpu",
        )
        self.nms_cfg = cfg.task.nms

    def forward(self, x):
        preds = self.model(x)
        heads = preds["Main"] if isinstance(preds, dict) else preds
        dets = PostProcess(self.converter, self.nms_cfg)({"Main": heads}, None)
        return torch.cat(dets, dim=0)  # Output shape: [N, 6]


class RawYoloExport(nn.Module):
    """
    YOLO Export without NMS (for flexible post-processing)
    Returns raw predictions: class logits, bboxes, and confidence scores
    """

    def __init__(self, model, cfg):
        super().__init__()
        self.model = model.eval()
        self.converter = create_converter(
            cfg.model.name,
            model,
            cfg.model.anchor,
            cfg.task.data.image_size,
            device="cpu",
        )

    def forward(self, x):
        preds = self.model(x)
        heads = preds["Main"] if isinstance(preds, dict) else preds

        # Convert model output to bbox format (without NMS)
        prediction = self.converter(heads)
        pred_class, _, pred_bbox = prediction[:3]
        pred_conf = prediction[3] if len(prediction) == 4 else None

        # Output raw predictions for external NMS processing
        # pred_class: [B, num_anchors, num_classes] - class logits (before sigmoid)
        # pred_bbox: [B, num_anchors, 4] - bounding boxes in xyxy format
        # pred_conf: [B, num_anchors, 1] - objectness confidence (sigmoid applied) or None

        if pred_conf is not None:
            return pred_class, pred_bbox, pred_conf
        else:
            return pred_class, pred_bbox


def export_full_onnx(ckpt_path, model_name, num_classes, output_file, opset_version=17):
    """Export ONNX model with NMS included"""
    print("ğŸš€ ONNXå¤‰æ›ã‚’é–‹å§‹ (NMSè¾¼ã¿)...")

    try:
        # 1. è¨­å®šèª­ã¿è¾¼ã¿
        print("ğŸ“‹ è¨­å®šã‚’èª­ã¿è¾¼ã¿ä¸­...")
        with initialize(config_path="yolo/config", version_base=None):
            cfg = compose(
                config_name="config.yaml",
                overrides=[
                    "task=inference",
                    f"model={model_name}",
                    f"dataset.class_num={num_classes}",
                ],
            )
        print(f"âœ… è¨­å®šèª­ã¿è¾¼ã¿å®Œäº† (ãƒ¢ãƒ‡ãƒ«: {model_name}, ã‚¯ãƒ©ã‚¹æ•°: {num_classes})")
        print(f"   - ç”»åƒã‚µã‚¤ã‚º: {cfg.task.data.image_size}")
        print(
            f"   - NMSè¨­å®š: min_confidence={cfg.task.nms.min_confidence}, min_iou={cfg.task.nms.min_iou}"
        )

        # 2. ãƒ¢ãƒ‡ãƒ«ä½œæˆ
        print("ğŸ—ï¸ ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆä¸­...")
        model = create_model(cfg.model, class_num=num_classes)
        print("âœ… ãƒ¢ãƒ‡ãƒ«ä½œæˆå®Œäº†")

        # 3. ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿
        print(f"ğŸ“¦ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿ä¸­: {ckpt_path}")
        ckpt = torch.load(ckpt_path, map_location="cpu")
        state_dict = ckpt["state_dict"]

        # Lightningå½¢å¼ã®ã‚­ãƒ¼åå¤‰æ› (model.model.* â†’ model.*)
        new_state_dict = {}
        for key, value in state_dict.items():
            if key.startswith("model."):
                new_key = key[6:]  # "model."ã‚’å‰Šé™¤
                new_state_dict[new_key] = value
            else:
                new_state_dict[key] = value

        # ãƒ¢ãƒ‡ãƒ«ã«é‡ã¿ã‚’èª­ã¿è¾¼ã¿
        missing_keys, unexpected_keys = model.load_state_dict(
            new_state_dict, strict=False
        )
        if missing_keys:
            print(f"âš ï¸ ä¸è¶³ã‚­ãƒ¼: {len(missing_keys)}å€‹")
        if unexpected_keys:
            print(f"âš ï¸ ä½™åˆ†ã‚­ãƒ¼: {len(unexpected_keys)}å€‹")
        print("âœ… ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿å®Œäº†")

        # 4. ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨ãƒ©ãƒƒãƒ‘ãƒ¼ä½œæˆ
        print("ğŸ”§ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨ãƒ©ãƒƒãƒ‘ãƒ¼ã‚’ä½œæˆä¸­...")
        wrapper = FullYoloExport(model, cfg).eval()

        # 5. ãƒ€ãƒŸãƒ¼å…¥åŠ›ä½œæˆ
        image_size = cfg.task.data.image_size
        dummy_input = torch.randn(1, 3, image_size[0], image_size[1])
        print(f"âœ… ãƒ€ãƒŸãƒ¼å…¥åŠ›ä½œæˆå®Œäº† (ã‚µã‚¤ã‚º: {dummy_input.shape})")

        # 6. ONNX Export
        print(f"ğŸ”„ ONNXå¤‰æ›ä¸­: {output_file}")
        torch.onnx.export(
            wrapper,
            dummy_input,
            output_file,
            opset_version=opset_version,
            input_names=["input"],
            output_names=["output"],
            dynamic_axes={
                "input": {0: "batch"},
            },
            verbose=False,
        )

        print(f"ğŸ‰ ONNXå¤‰æ›å®Œäº†: {output_file}")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback

        traceback.print_exc()


def export_raw_onnx(ckpt_path, model_name, num_classes, output_file, opset_version=17):
    """Export ONNX model without NMS for flexible post-processing"""
    print("ğŸš€ ONNXå¤‰æ›ã‚’é–‹å§‹ (NMSç„¡ã—)...")

    try:
        # 1. è¨­å®šèª­ã¿è¾¼ã¿
        print("ğŸ“‹ è¨­å®šã‚’èª­ã¿è¾¼ã¿ä¸­...")
        with initialize(config_path="yolo/config", version_base=None):
            cfg = compose(
                config_name="config.yaml",
                overrides=[
                    "task=inference",
                    f"model={model_name}",
                    f"dataset.class_num={num_classes}",
                ],
            )
        print(f"âœ… è¨­å®šèª­ã¿è¾¼ã¿å®Œäº† (ãƒ¢ãƒ‡ãƒ«: {model_name}, ã‚¯ãƒ©ã‚¹æ•°: {num_classes})")
        print(f"   - ç”»åƒã‚µã‚¤ã‚º: {cfg.task.data.image_size}")

        # 2. ãƒ¢ãƒ‡ãƒ«ä½œæˆ
        print("ğŸ—ï¸ ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆä¸­...")
        model = create_model(cfg.model, class_num=num_classes)
        print("âœ… ãƒ¢ãƒ‡ãƒ«ä½œæˆå®Œäº†")

        # 3. ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿
        print(f"ğŸ“¦ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿ä¸­: {ckpt_path}")
        ckpt = torch.load(ckpt_path, map_location="cpu")
        state_dict = ckpt["state_dict"]

        # Lightningå½¢å¼ã®ã‚­ãƒ¼åå¤‰æ› (model.model.* â†’ model.*)
        new_state_dict = {}
        for key, value in state_dict.items():
            if key.startswith("model."):
                new_key = key[6:]  # "model."ã‚’å‰Šé™¤
                new_state_dict[new_key] = value
            else:
                new_state_dict[key] = value

        # ãƒ¢ãƒ‡ãƒ«ã«é‡ã¿ã‚’èª­ã¿è¾¼ã¿
        missing_keys, unexpected_keys = model.load_state_dict(
            new_state_dict, strict=False
        )
        if missing_keys:
            print(f"âš ï¸ ä¸è¶³ã‚­ãƒ¼: {len(missing_keys)}å€‹")
        if unexpected_keys:
            print(f"âš ï¸ ä½™åˆ†ã‚­ãƒ¼: {len(unexpected_keys)}å€‹")
        print("âœ… ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿å®Œäº†")

        # 4. ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨ãƒ©ãƒƒãƒ‘ãƒ¼ä½œæˆ (NMSç„¡ã—)
        print("ğŸ”§ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨ãƒ©ãƒƒãƒ‘ãƒ¼ã‚’ä½œæˆä¸­ (NMSç„¡ã—)...")
        wrapper = RawYoloExport(model, cfg).eval()

        # 5. ãƒ€ãƒŸãƒ¼å…¥åŠ›ä½œæˆ
        image_size = cfg.task.data.image_size
        dummy_input = torch.randn(1, 3, image_size[0], image_size[1])
        print(f"âœ… ãƒ€ãƒŸãƒ¼å…¥åŠ›ä½œæˆå®Œäº† (ã‚µã‚¤ã‚º: {dummy_input.shape})")

        # 6. å‡ºåŠ›ãƒ†ã‚¹ãƒˆ
        print("ğŸ§ª å‡ºåŠ›å½¢çŠ¶ãƒ†ã‚¹ãƒˆä¸­...")
        with torch.no_grad():
            outputs = wrapper(dummy_input)
            if isinstance(outputs, tuple):
                if len(outputs) == 3:
                    pred_class, pred_bbox, pred_conf = outputs
                    print(f"   - pred_class: {pred_class.shape} (ã‚¯ãƒ©ã‚¹ã‚¹ã‚³ã‚¢)")
                    print(f"   - pred_bbox: {pred_bbox.shape} (ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹)")
                    print(f"   - pred_conf: {pred_conf.shape} (ä¿¡é ¼åº¦)")
                    output_names = ["pred_class", "pred_bbox", "pred_conf"]
                else:
                    pred_class, pred_bbox = outputs
                    print(f"   - pred_class: {pred_class.shape} (ã‚¯ãƒ©ã‚¹ã‚¹ã‚³ã‚¢)")
                    print(f"   - pred_bbox: {pred_bbox.shape} (ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹)")
                    output_names = ["pred_class", "pred_bbox"]

        # 7. ONNX Export
        print(f"ğŸ”„ ONNXå¤‰æ›ä¸­: {output_file}")
        torch.onnx.export(
            wrapper,
            dummy_input,
            output_file,
            opset_version=opset_version,
            input_names=["input"],
            output_names=output_names,
            dynamic_axes={
                "input": {0: "batch"},
                output_names[0]: {0: "batch"},
                output_names[1]: {0: "batch"},
            },
            verbose=False,
        )

        print(f"ğŸ‰ ONNXå¤‰æ›å®Œäº†: {output_file}")
        print("   - NMSå‡¦ç†ã¯æ¨è«–æ™‚ã«å¤–éƒ¨ã§å®Ÿè¡Œã—ã¦ãã ã•ã„")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback

        traceback.print_exc()


def main():
    parser = argparse.ArgumentParser(
        description="YOLOv9 ONNX Export",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Export with NMS (full mode)
  python -m yolo.tools.onnx_export --checkpoint runs/train/exp/best.ckpt --model-name v9-s --num-classes 2

  # Export without NMS (raw mode)
  python -m yolo.tools.onnx_export -p runs/train/exp/best.ckpt -m v9-s -n 2 --mode raw

  # Custom output and opset version
  python -m yolo.tools.onnx_export -p best.ckpt -m v9-c -n 80 -o model.onnx --opset-version 17
""",
    )

    parser.add_argument(
        "--checkpoint",
        "-p",
        type=str,
        required=True,
        help="Path to checkpoint file (.ckpt)",
    )
    parser.add_argument(
        "--model-name",
        "-m",
        type=str,
        required=True,
        help="Model name (e.g., v9-s, v9-c, v9-m)",
    )
    parser.add_argument(
        "--num-classes",
        "-n",
        type=int,
        required=True,
        help="Number of classes",
    )
    parser.add_argument(
        "--output",
        "-o",
        type=str,
        default=None,
        help="Output ONNX file path (default: auto-generated based on mode)",
    )
    parser.add_argument(
        "--mode",
        choices=["full", "raw"],
        default="full",
        help="Export mode: 'full' (with NMS) or 'raw' (without NMS) [default: full]",
    )
    parser.add_argument(
        "--opset-version",
        type=int,
        default=17,
        help="ONNX opset version [default: 17]",
    )

    args = parser.parse_args()

    # Generate output filename if not specified
    if args.output is None:
        checkpoint_name = Path(args.checkpoint).stem
        suffix = "_raw" if args.mode == "raw" else "_full"
        args.output = f"{checkpoint_name}{suffix}.onnx"

    print(f"{'='*60}")
    print(f"YOLOv9 ONNX Export")
    print(f"{'='*60}")
    print(f"Checkpoint: {args.checkpoint}")
    print(f"Model: {args.model_name}")
    print(f"Classes: {args.num_classes}")
    print(f"Mode: {args.mode}")
    print(f"Output: {args.output}")
    print(f"ONNX Opset: {args.opset_version}")
    print(f"{'='*60}\n")

    # Export based on mode
    if args.mode == "full":
        export_full_onnx(
            args.checkpoint,
            args.model_name,
            args.num_classes,
            args.output,
            args.opset_version,
        )
    else:
        export_raw_onnx(
            args.checkpoint,
            args.model_name,
            args.num_classes,
            args.output,
            args.opset_version,
        )


if __name__ == "__main__":
    main()