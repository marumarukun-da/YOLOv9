#!/usr/bin/env python3
"""
YOLOv9 ONNX Inference Script for current repository
Supports inference using exported ONNX model with or without NMS.
"""

import argparse
from datetime import datetime
from pathlib import Path

import cv2
import numpy as np
import onnxruntime as ort
from PIL import Image

# Configuration - ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã«åˆã‚ã›ã¦è¨­å®š
ONNX_PATH = "yolov9_full.onnx"
ONNX_RAW_PATH = "yolov9_full_raw.onnx"  # NMSç„¡ã—ãƒ¢ãƒ‡ãƒ«
IMG_SIZE = 640  # å¤‰æ›æ™‚ã¨åŒã˜ã‚µã‚¤ã‚º
CLASS_LIST = ["person", "head"]  # mitococa_v9ã®2ã‚¯ãƒ©ã‚¹
DEFAULT_IMAGE_PATH = "dataset/mitococa_v9/images/val"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç”»åƒãƒ‘ã‚¹

# NMS Parameters (for raw mode)
DEFAULT_MIN_CONFIDENCE = 0.25
DEFAULT_MIN_IOU = 0.45
DEFAULT_MAX_BBOX = 300


def apply_nms(
    pred_class,
    pred_bbox,
    pred_conf=None,
    min_confidence=DEFAULT_MIN_CONFIDENCE,
    min_iou=DEFAULT_MIN_IOU,
    max_bbox=DEFAULT_MAX_BBOX,
):
    """
    Apply NMS to raw ONNX model outputs

    Args:
        pred_class: [B, num_anchors, num_classes] - class logits (before sigmoid)
        pred_bbox: [B, num_anchors, 4] - bounding boxes in xyxy format
        pred_conf: [B, num_anchors, 1] - objectness confidence (sigmoid applied) or None
        min_confidence: minimum confidence threshold
        min_iou: minimum IoU threshold for NMS
        max_bbox: maximum number of bboxes to return

    Returns:
        List of [N, 6] arrays (cls, x1, y1, x2, y2, conf) for each batch
    """
    # Apply sigmoid to class logits
    cls_dist = 1 / (1 + np.exp(-pred_class))  # sigmoid

    # Multiply by objectness confidence if available
    if pred_conf is not None:
        cls_dist = cls_dist * pred_conf

    # Find valid detections above confidence threshold
    batch_size = cls_dist.shape[0]
    all_detections = []

    for batch_idx in range(batch_size):
        # Get predictions for this batch
        batch_cls = cls_dist[batch_idx]  # [num_anchors, num_classes]
        batch_bbox = pred_bbox[batch_idx]  # [num_anchors, 4]

        # Find all detections above threshold
        valid_mask = batch_cls > min_confidence
        valid_indices = np.where(valid_mask)

        if len(valid_indices[0]) == 0:
            all_detections.append(np.zeros((0, 6), dtype=np.float32))
            continue

        anchor_idx = valid_indices[0]
        class_idx = valid_indices[1]
        confidences = batch_cls[valid_mask]
        boxes = batch_bbox[anchor_idx]

        # Apply NMS per class
        keep_indices = []
        for cls_id in np.unique(class_idx):
            cls_mask = class_idx == cls_id
            cls_boxes = boxes[cls_mask]
            cls_conf = confidences[cls_mask]
            cls_anchor_idx = np.where(cls_mask)[0]

            # NMS using cv2 (compatible with torchvision.ops.batched_nms logic)
            indices = cv2.dnn.NMSBoxes(
                cls_boxes.tolist(), cls_conf.tolist(), min_confidence, min_iou
            )

            if len(indices) > 0:
                indices = indices.flatten()
                keep_indices.extend(cls_anchor_idx[indices].tolist())

        if len(keep_indices) == 0:
            all_detections.append(np.zeros((0, 6), dtype=np.float32))
            continue

        # Collect results
        keep_indices = np.array(keep_indices)
        final_boxes = boxes[keep_indices]
        final_conf = confidences[keep_indices]
        final_cls = class_idx[keep_indices]

        # Sort by confidence and limit to max_bbox
        sort_idx = np.argsort(-final_conf)[:max_bbox]

        # Format: [cls, x1, y1, x2, y2, conf]
        detections = np.column_stack(
            [final_cls[sort_idx], final_boxes[sort_idx], final_conf[sort_idx]]
        )

        all_detections.append(detections.astype(np.float32))

    return all_detections


def letterbox(pil_img, size=IMG_SIZE, color=(114, 114, 114)):
    """
    Resize the image with aspect ratio preserved and pad to square (same as training).
    Returns:
    - padded PIL.Image (sizeÃ—size)
    - r float: scaling ratio
    - pad_w int : width padding (left-right)
    - pad_h int : height padding (top-bottom)
    """
    w0, h0 = pil_img.size
    r = min(size / w0, size / h0)
    nw, nh = int(w0 * r), int(h0 * r)
    resized = pil_img.resize((nw, nh), Image.LANCZOS)
    pad_w, pad_h = (size - nw) // 2, (size - nh) // 2
    canvas = Image.new("RGB", (size, size), color)
    canvas.paste(resized, (pad_w, pad_h))
    return canvas, r, pad_w, pad_h


def get_image_list(path_str):
    """
    If path_str is a file, return [path_str];
    If it's a folder, return a list of all common image file paths.
    """
    p = Path(path_str)
    if p.is_file():
        return [p]
    elif p.is_dir():
        exts = {".jpg", ".jpeg", ".png", ".bmp"}
        return sorted([x for x in p.iterdir() if x.suffix.lower() in exts])
    else:
        raise FileNotFoundError(f"Path not found: {path_str}")


def test_onnx_model(onnx_path, is_raw=False):
    """
    æ®µéšçš„ãƒ†ã‚¹ãƒˆ: ONNXãƒ¢ãƒ‡ãƒ«ã®åŸºæœ¬å‹•ä½œç¢ºèª

    Args:
        onnx_path: Path to ONNX model
        is_raw: True if model outputs raw predictions (without NMS)
    """
    print("ğŸ§ª ONNXæ¨è«–ãƒ†ã‚¹ãƒˆé–‹å§‹...")

    try:
        # 1. ONNXãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
        print(f"ğŸ“¦ ONNXãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: {onnx_path}")
        if not Path(onnx_path).exists():
            raise FileNotFoundError(f"ONNXãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {onnx_path}")

        print(
            f"âœ… ONNXãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª (ã‚µã‚¤ã‚º: {Path(onnx_path).stat().st_size / 1024 / 1024:.1f}MB)"
        )

        # 2. ONNXRuntimeã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
        print("ğŸ”§ ONNXRuntimeã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ...")
        providers = (
            ["CUDAExecutionProvider"]
            if "CUDAExecutionProvider" in ort.get_available_providers()
            else ["CPUExecutionProvider"]
        )
        print(f"   - ä½¿ç”¨ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {providers[0]}")

        sess = ort.InferenceSession(onnx_path, providers=providers)

        # 3. ãƒ¢ãƒ‡ãƒ«ã®å…¥å‡ºåŠ›æƒ…å ±ç¢ºèª
        print("ğŸ“Š ãƒ¢ãƒ‡ãƒ«æƒ…å ±:")
        inp_name = sess.get_inputs()[0].name
        inp_shape = sess.get_inputs()[0].shape

        print(f"   - å…¥åŠ›å: {inp_name}")
        print(f"   - å…¥åŠ›å½¢çŠ¶: {inp_shape}")

        output_names = []
        for i, out in enumerate(sess.get_outputs()):
            print(f"   - å‡ºåŠ›{i}: {out.name}, å½¢çŠ¶: {out.shape}")
            output_names.append(out.name)

        # 4. ãƒ€ãƒŸãƒ¼å…¥åŠ›ã§ãƒ†ã‚¹ãƒˆæ¨è«–
        print("ğŸ”„ ãƒ€ãƒŸãƒ¼å…¥åŠ›ã§ãƒ†ã‚¹ãƒˆæ¨è«–...")
        dummy_input = np.random.rand(1, 3, IMG_SIZE, IMG_SIZE).astype(np.float32)

        start_time = datetime.now()
        outputs = sess.run(None, {inp_name: dummy_input})
        end_time = datetime.now()
        inference_time = (end_time - start_time).total_seconds() * 1000

        print("âœ… æ¨è«–æˆåŠŸ:")
        print(f"   - æ¨è«–æ™‚é–“: {inference_time:.1f}ms")

        if is_raw:
            # Raw model: multiple outputs (pred_class, pred_bbox, pred_conf)
            print(f"   - å‡ºåŠ›æ•°: {len(outputs)}")
            for i, out in enumerate(outputs):
                print(f"   - å‡ºåŠ›{i}å½¢çŠ¶: {out.shape}")

            # Test NMS on raw outputs
            if len(outputs) == 3:
                dets = apply_nms(outputs[0], outputs[1], outputs[2])
            else:
                dets = apply_nms(outputs[0], outputs[1])
            print(f"   - NMSå¾Œæ¤œå‡ºæ•°: {dets[0].shape[0]}å€‹")
        else:
            # Full model: single output with NMS already applied
            dets = outputs[0]
            print(f"   - å‡ºåŠ›å½¢çŠ¶: {dets.shape}")
            print(f"   - æ¤œå‡ºæ•°: {dets.shape[0]}å€‹")

        return sess, inp_name, is_raw

    except Exception as e:
        print(f"âŒ ONNXãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback

        traceback.print_exc()
        return None, None, False


def inference_single_image(
    sess,
    inp_name,
    img_path,
    is_raw=False,
    min_confidence=DEFAULT_MIN_CONFIDENCE,
    min_iou=DEFAULT_MIN_IOU,
    max_bbox=DEFAULT_MAX_BBOX,
    save_result=True,
):
    """
    å˜ä¸€ç”»åƒã§ã®ONNXæ¨è«–

    Args:
        sess: ONNX Runtime session
        inp_name: Input tensor name
        img_path: Path to image
        is_raw: True if model outputs raw predictions (without NMS)
        min_confidence: Confidence threshold for NMS (raw mode only)
        min_iou: IoU threshold for NMS (raw mode only)
        max_bbox: Maximum number of detections (raw mode only)
        save_result: Whether to save result image
    """
    try:
        print(f"ğŸ–¼ï¸ æ¨è«–å®Ÿè¡Œ: {img_path}")

        # 1. ç”»åƒèª­ã¿è¾¼ã¿ãƒ»å‰å‡¦ç†
        pil_img = Image.open(img_path).convert("RGB")
        print(f"   - å…ƒç”»åƒã‚µã‚¤ã‚º: {pil_img.size}")

        img_pad, r, pad_w, pad_h = letterbox(pil_img, IMG_SIZE)

        # æ­£è¦åŒ– & æ¬¡å…ƒå¤‰æ›
        inp = np.array(img_pad, dtype=np.float32) / 255.0
        inp = inp.transpose(2, 0, 1)[None, ...]  # [1, 3, H, W]

        # 2. ONNXæ¨è«–
        start_time = datetime.now()
        outputs = sess.run(None, {inp_name: inp})
        end_time = datetime.now()
        inference_time = (end_time - start_time).total_seconds() * 1000

        print(f"   - æ¨è«–æ™‚é–“: {inference_time:.1f}ms")

        # 3. Process outputs based on model type
        if is_raw:
            # Apply NMS to raw outputs
            if len(outputs) == 3:
                dets_list = apply_nms(
                    outputs[0],
                    outputs[1],
                    outputs[2],
                    min_confidence,
                    min_iou,
                    max_bbox,
                )
            else:
                dets_list = apply_nms(
                    outputs[0], outputs[1], None, min_confidence, min_iou, max_bbox
                )
            dets = dets_list[0]  # Get first batch
            print(f"   - NMSå¾Œæ¤œå‡ºæ•°: {dets.shape[0]}å€‹")
        else:
            # Full model already has NMS applied
            dets = outputs[0]
            print(f"   - æ¤œå‡ºæ•°: {dets.shape[0]}å€‹")

        if dets.shape[0] == 0:
            print("   - æ¤œå‡ºçµæœãªã—")
            return None

        # 4. çµæœã®åº§æ¨™å¤‰æ›ãƒ»æç”»
        img_bgr = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
        valid_detections = 0

        for det in dets:
            cls, x1, y1, x2, y2, conf = det

            # åº§æ¨™ã‚’å…ƒç”»åƒã«æˆ»ã™
            xx1 = (x1 - pad_w) / r
            yy1 = (y1 - pad_h) / r
            xx2 = (x2 - pad_w) / r
            yy2 = (y2 - pad_h) / r

            # ç”»åƒç¯„å›²å†…ã«ã‚¯ãƒªãƒƒãƒ—
            W0, H0 = pil_img.size
            xx1 = max(min(xx1, W0 - 1), 0)
            yy1 = max(min(yy1, H0 - 1), 0)
            xx2 = max(min(xx2, W0 - 1), 0)
            yy2 = max(min(yy2, H0 - 1), 0)

            # æœ‰åŠ¹ãªæ¤œå‡ºã®ã¿æç”»
            if xx2 > xx1 and yy2 > yy1:
                xi1, yi1, xi2, yi2 = map(int, (xx1, yy1, xx2, yy2))

                # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æç”»
                cv2.rectangle(img_bgr, (xi1, yi1), (xi2, yi2), (0, 255, 0), 2)

                # ãƒ©ãƒ™ãƒ«æç”»
                cls_name = (
                    CLASS_LIST[int(cls)]
                    if int(cls) < len(CLASS_LIST)
                    else f"Class{int(cls)}"
                )
                label = f"{cls_name} {conf:.2f}"
                cv2.putText(
                    img_bgr,
                    label,
                    (xi1, yi1 - 6),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.5,
                    (0, 255, 0),
                    1,
                )
                valid_detections += 1

        print(f"   - æœ‰åŠ¹æ¤œå‡ºæ•°: {valid_detections}å€‹")

        # 5. çµæœä¿å­˜
        if save_result:
            out_dir = Path("outputs")
            out_dir.mkdir(exist_ok=True)
            suffix = "_raw" if is_raw else ""
            out_path = out_dir / f"onnx_result{suffix}_{Path(img_path).stem}.jpg"
            cv2.imwrite(str(out_path), img_bgr)
            print(f"   - çµæœä¿å­˜: {out_path}")

        return img_bgr

    except Exception as e:
        print(f"âŒ æ¨è«–ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback

        traceback.print_exc()
        return None


def main():
    parser = argparse.ArgumentParser(description="YOLOv9 ONNXæ¨è«–")
    parser.add_argument(
        "--image",
        "-i",
        default=DEFAULT_IMAGE_PATH,
        help="æ¨è«–å¯¾è±¡ã®ç”»åƒã¾ãŸã¯ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹",
    )
    parser.add_argument(
        "--model",
        "-m",
        choices=["full", "raw"],
        default="full",
        help="ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: 'full' (NMSè¾¼ã¿) or 'raw' (NMSç„¡ã—)",
    )
    parser.add_argument(
        "--confidence",
        "-c",
        type=float,
        default=DEFAULT_MIN_CONFIDENCE,
        help="ä¿¡é ¼åº¦é–¾å€¤ (raw mode only)",
    )
    parser.add_argument(
        "--iou", type=float, default=DEFAULT_MIN_IOU, help="IoUé–¾å€¤ (raw mode only)"
    )
    parser.add_argument(
        "--max-det",
        type=int,
        default=DEFAULT_MAX_BBOX,
        help="æœ€å¤§æ¤œå‡ºæ•° (raw mode only)",
    )
    parser.add_argument(
        "--test-only", action="store_true", help="åŸºæœ¬å‹•ä½œãƒ†ã‚¹ãƒˆã®ã¿å®Ÿè¡Œ"
    )
    parser.add_argument("--display", action="store_true", help="çµæœã‚’ç”»é¢è¡¨ç¤º")

    args = parser.parse_args()

    # Determine ONNX path and mode
    is_raw = args.model == "raw"
    onnx_path = ONNX_RAW_PATH if is_raw else ONNX_PATH

    print(f"ãƒ¢ãƒ¼ãƒ‰: {'RAW (NMSç„¡ã—)' if is_raw else 'FULL (NMSè¾¼ã¿)'}")
    if is_raw:
        print(
            f"NMSãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: confidence={args.confidence}, iou={args.iou}, max_det={args.max_det}"
        )

    # 1. åŸºæœ¬ãƒ†ã‚¹ãƒˆ
    sess, inp_name, is_raw_model = test_onnx_model(onnx_path, is_raw)
    if sess is None or inp_name is None:
        print("ğŸ’¥ ONNXãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆå¤±æ•—")
        return

    if args.test_only:
        print("ğŸ‰ åŸºæœ¬ãƒ†ã‚¹ãƒˆå®Œäº†")
        return

    # 2. å®Ÿéš›ã®ç”»åƒã§æ¨è«–
    try:
        img_paths = get_image_list(args.image)
        print(f"ğŸ“¸ æ¨è«–å¯¾è±¡: {len(img_paths)}æšã®ç”»åƒ")

        for img_path in img_paths[:5]:  # æœ€åˆã®5æšã‚’ãƒ†ã‚¹ãƒˆ
            result_img = inference_single_image(
                sess,
                inp_name,
                img_path,
                is_raw=is_raw_model,
                min_confidence=args.confidence,
                min_iou=args.iou,
                max_bbox=args.max_det,
            )

            if result_img is not None and args.display:
                # çµæœè¡¨ç¤ºï¼ˆã‚µã‚¤ã‚ºã‚’åŠåˆ†ã«ç¸®å°ï¼‰
                h, w = result_img.shape[:2]
                disp = cv2.resize(
                    result_img, (w // 2, h // 2), interpolation=cv2.INTER_LINEAR
                )
                cv2.imshow(f"ONNXæ¨è«–çµæœ: {img_path.name}", disp)
                print("   - ç”»é¢è¡¨ç¤ºä¸­ï¼ˆã‚­ãƒ¼å…¥åŠ›ã§æ¬¡ã¸ï¼‰")
                cv2.waitKey(0)
                cv2.destroyAllWindows()

        print("ğŸ‰ ONNXæ¨è«–å®Œäº†")

    except Exception as e:
        print(f"âŒ ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
