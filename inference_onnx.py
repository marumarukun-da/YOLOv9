#!/usr/bin/env python3
"""
YOLOv9 ONNX Inference Script for current repository
Supports inference using exported ONNX model (yolov9_full.onnx) with complete post-processing.
"""

import cv2
import numpy as np
import onnxruntime as ort
from PIL import Image
from pathlib import Path
from datetime import datetime
import argparse

# Configuration - ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã«åˆã‚ã›ã¦è¨­å®š
ONNX_PATH = "yolov9_full.onnx"
IMG_SIZE = 640  # å¤‰æ›æ™‚ã¨åŒã˜ã‚µã‚¤ã‚º
CLASS_LIST = ["person", "head"]  # mitococa_v9ã®2ã‚¯ãƒ©ã‚¹
DEFAULT_IMAGE_PATH = "dataset/mitococa_v9/images/val"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç”»åƒãƒ‘ã‚¹

def letterbox(pil_img, size=IMG_SIZE, color=(114, 114, 114)):
    """
    Resize the image with aspect ratio preserved and pad to square (same as training).
    Returns:
    - padded PIL.Image (sizeÃ—size)
    - r float: scaling ratio
    - pad_w int : width padding (left-right)
    - pad_h int : height padding (top-bottom)
    """
    w0, h0 = pil_img.size
    r = min(size / w0, size / h0)
    nw, nh = int(w0 * r), int(h0 * r)
    resized = pil_img.resize((nw, nh), Image.LANCZOS)
    pad_w, pad_h = (size - nw) // 2, (size - nh) // 2
    canvas = Image.new("RGB", (size, size), color)
    canvas.paste(resized, (pad_w, pad_h))
    return canvas, r, pad_w, pad_h

def get_image_list(path_str):
    """
    If path_str is a file, return [path_str];
    If it's a folder, return a list of all common image file paths.
    """
    p = Path(path_str)
    if p.is_file():
        return [p]
    elif p.is_dir():
        exts = {".jpg", ".jpeg", ".png", ".bmp"}
        return sorted([x for x in p.iterdir() if x.suffix.lower() in exts])
    else:
        raise FileNotFoundError(f"Path not found: {path_str}")

def test_onnx_model():
    """
    æ®µéšçš„ãƒ†ã‚¹ãƒˆ: ONNXãƒ¢ãƒ‡ãƒ«ã®åŸºæœ¬å‹•ä½œç¢ºèª
    """
    print("ğŸ§ª ONNXæ¨è«–ãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    try:
        # 1. ONNXãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
        print(f"ğŸ“¦ ONNXãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: {ONNX_PATH}")
        if not Path(ONNX_PATH).exists():
            raise FileNotFoundError(f"ONNXãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {ONNX_PATH}")
        
        print(f"âœ… ONNXãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª (ã‚µã‚¤ã‚º: {Path(ONNX_PATH).stat().st_size / 1024 / 1024:.1f}MB)")
        
        # 2. ONNXRuntimeã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
        print("ğŸ”§ ONNXRuntimeã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ...")
        providers = ["CUDAExecutionProvider"] if "CUDAExecutionProvider" in ort.get_available_providers() \
                   else ["CPUExecutionProvider"]
        print(f"   - ä½¿ç”¨ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {providers[0]}")
        
        sess = ort.InferenceSession(ONNX_PATH, providers=providers)
        
        # 3. ãƒ¢ãƒ‡ãƒ«ã®å…¥å‡ºåŠ›æƒ…å ±ç¢ºèª
        print("ğŸ“Š ãƒ¢ãƒ‡ãƒ«æƒ…å ±:")
        inp_name = sess.get_inputs()[0].name
        inp_shape = sess.get_inputs()[0].shape
        out_name = sess.get_outputs()[0].name
        out_shape = sess.get_outputs()[0].shape
        
        print(f"   - å…¥åŠ›å: {inp_name}")
        print(f"   - å…¥åŠ›å½¢çŠ¶: {inp_shape}")
        print(f"   - å‡ºåŠ›å: {out_name}")
        print(f"   - å‡ºåŠ›å½¢çŠ¶: {out_shape}")
        
        # 4. ãƒ€ãƒŸãƒ¼å…¥åŠ›ã§ãƒ†ã‚¹ãƒˆæ¨è«–
        print("ğŸ”„ ãƒ€ãƒŸãƒ¼å…¥åŠ›ã§ãƒ†ã‚¹ãƒˆæ¨è«–...")
        dummy_input = np.random.rand(1, 3, IMG_SIZE, IMG_SIZE).astype(np.float32)
        
        start_time = datetime.now()
        dets = sess.run(None, {inp_name: dummy_input})[0]
        end_time = datetime.now()
        inference_time = (end_time - start_time).total_seconds() * 1000
        
        print(f"âœ… æ¨è«–æˆåŠŸ:")
        print(f"   - æ¨è«–æ™‚é–“: {inference_time:.1f}ms")
        print(f"   - å‡ºåŠ›å½¢çŠ¶: {dets.shape}")
        print(f"   - æ¤œå‡ºæ•°: {dets.shape[0]}å€‹")
        
        return sess, inp_name
        
    except Exception as e:
        print(f"âŒ ONNXãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return None, None

def inference_single_image(sess, inp_name, img_path, save_result=True):
    """
    å˜ä¸€ç”»åƒã§ã®ONNXæ¨è«–
    """
    try:
        print(f"ğŸ–¼ï¸ æ¨è«–å®Ÿè¡Œ: {img_path}")
        
        # 1. ç”»åƒèª­ã¿è¾¼ã¿ãƒ»å‰å‡¦ç†
        pil_img = Image.open(img_path).convert("RGB")
        print(f"   - å…ƒç”»åƒã‚µã‚¤ã‚º: {pil_img.size}")
        
        img_pad, r, pad_w, pad_h = letterbox(pil_img, IMG_SIZE)
        
        # æ­£è¦åŒ– & æ¬¡å…ƒå¤‰æ›
        inp = np.array(img_pad, dtype=np.float32) / 255.0
        inp = inp.transpose(2, 0, 1)[None, ...]  # [1, 3, H, W]
        
        # 2. ONNXæ¨è«–
        start_time = datetime.now()
        dets = sess.run(None, {inp_name: inp})[0]  # [num_detections, 6]
        end_time = datetime.now()
        inference_time = (end_time - start_time).total_seconds() * 1000
        
        print(f"   - æ¨è«–æ™‚é–“: {inference_time:.1f}ms")
        print(f"   - æ¤œå‡ºæ•°: {dets.shape[0]}å€‹")
        
        if dets.shape[0] == 0:
            print("   - æ¤œå‡ºçµæœãªã—")
            return
        
        # 3. çµæœã®åº§æ¨™å¤‰æ›ãƒ»æç”»
        img_bgr = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
        valid_detections = 0
        
        for det in dets:
            cls, x1, y1, x2, y2, conf = det
            
            # åº§æ¨™ã‚’å…ƒç”»åƒã«æˆ»ã™
            xx1 = (x1 - pad_w) / r
            yy1 = (y1 - pad_h) / r
            xx2 = (x2 - pad_w) / r
            yy2 = (y2 - pad_h) / r
            
            # ç”»åƒç¯„å›²å†…ã«ã‚¯ãƒªãƒƒãƒ—
            W0, H0 = pil_img.size
            xx1 = max(min(xx1, W0 - 1), 0)
            yy1 = max(min(yy1, H0 - 1), 0)
            xx2 = max(min(xx2, W0 - 1), 0)
            yy2 = max(min(yy2, H0 - 1), 0)
            
            # æœ‰åŠ¹ãªæ¤œå‡ºã®ã¿æç”»
            if xx2 > xx1 and yy2 > yy1:
                xi1, yi1, xi2, yi2 = map(int, (xx1, yy1, xx2, yy2))
                
                # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æç”»
                cv2.rectangle(img_bgr, (xi1, yi1), (xi2, yi2), (0, 255, 0), 2)
                
                # ãƒ©ãƒ™ãƒ«æç”»
                cls_name = CLASS_LIST[int(cls)] if int(cls) < len(CLASS_LIST) else f"Class{int(cls)}"
                label = f"{cls_name} {conf:.2f}"
                cv2.putText(
                    img_bgr, label, (xi1, yi1 - 6),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1
                )
                valid_detections += 1
        
        print(f"   - æœ‰åŠ¹æ¤œå‡ºæ•°: {valid_detections}å€‹")
        
        # 4. çµæœä¿å­˜
        if save_result:
            out_dir = Path("outputs")
            out_dir.mkdir(exist_ok=True)
            out_path = out_dir / f"onnx_result_{Path(img_path).stem}.jpg"
            cv2.imwrite(str(out_path), img_bgr)
            print(f"   - çµæœä¿å­˜: {out_path}")
        
        return img_bgr
        
    except Exception as e:
        print(f"âŒ æ¨è«–ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    parser = argparse.ArgumentParser(description="YOLOv9 ONNXæ¨è«–")
    parser.add_argument("--image", "-i", default=DEFAULT_IMAGE_PATH,
                       help="æ¨è«–å¯¾è±¡ã®ç”»åƒã¾ãŸã¯ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹")
    parser.add_argument("--test-only", action="store_true",
                       help="åŸºæœ¬å‹•ä½œãƒ†ã‚¹ãƒˆã®ã¿å®Ÿè¡Œ")
    parser.add_argument("--display", action="store_true",
                       help="çµæœã‚’ç”»é¢è¡¨ç¤º")
    
    args = parser.parse_args()
    
    # 1. åŸºæœ¬ãƒ†ã‚¹ãƒˆ
    sess, inp_name = test_onnx_model()
    if sess is None or inp_name is None:
        print("ğŸ’¥ ONNXãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆå¤±æ•—")
        return
    
    if args.test_only:
        print("ğŸ‰ åŸºæœ¬ãƒ†ã‚¹ãƒˆå®Œäº†")
        return
    
    # 2. å®Ÿéš›ã®ç”»åƒã§æ¨è«–
    try:
        img_paths = get_image_list(args.image)
        print(f"ğŸ“¸ æ¨è«–å¯¾è±¡: {len(img_paths)}æšã®ç”»åƒ")
        
        for img_path in img_paths[:5]:  # æœ€åˆã®5æšã‚’ãƒ†ã‚¹ãƒˆ
            result_img = inference_single_image(sess, inp_name, img_path)
            
            if result_img is not None and args.display:
                # çµæœè¡¨ç¤ºï¼ˆã‚µã‚¤ã‚ºã‚’åŠåˆ†ã«ç¸®å°ï¼‰
                h, w = result_img.shape[:2]
                disp = cv2.resize(result_img, (w // 2, h // 2), interpolation=cv2.INTER_LINEAR)
                cv2.imshow(f"ONNXæ¨è«–çµæœ: {img_path.name}", disp)
                print("   - ç”»é¢è¡¨ç¤ºä¸­ï¼ˆã‚­ãƒ¼å…¥åŠ›ã§æ¬¡ã¸ï¼‰")
                cv2.waitKey(0)
                cv2.destroyAllWindows()
        
        print("ğŸ‰ ONNXæ¨è«–å®Œäº†")
        
    except Exception as e:
        print(f"âŒ ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()