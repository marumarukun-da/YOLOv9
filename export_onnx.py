#!/usr/bin/env python3
"""
YOLOv9 ONNX Export Script for current repository
"""

import torch
import torch.nn as nn
from hydra import compose, initialize

from yolo.model.yolo import create_model
from yolo.utils.bounding_box_utils import create_converter
from yolo.utils.model_utils import PostProcess

# Configuration
NUM_CLASSES = 2  # mitococa_v9ã¯2ã‚¯ãƒ©ã‚¹ï¼ˆperson, headï¼‰
CKPT_PATH = "runs/train/mitococa_v9_10epoch/best-epoch=09-map=0.3239.ckpt"
MODEL_NAME = "v9-s"  # ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«åï¼ˆoverrides.yamlã‚ˆã‚Šç¢ºèªï¼‰
EXPORT_ONNX_FILE = "yolov9_full.onnx"


class FullYoloExport(nn.Module):
    def __init__(self, model, cfg):
        super().__init__()
        self.model = model.eval()
        self.converter = create_converter(
            cfg.model.name,
            model,
            cfg.model.anchor,
            cfg.task.data.image_size,
            device="cpu",
        )
        self.nms_cfg = cfg.task.nms

    def forward(self, x):
        preds = self.model(x)
        heads = preds["Main"] if isinstance(preds, dict) else preds
        dets = PostProcess(self.converter, self.nms_cfg)({"Main": heads}, None)
        return torch.cat(dets, dim=0)  # Output shape: [N, 6]


class RawYoloExport(nn.Module):
    """
    YOLO Export without NMS (for flexible post-processing)
    Returns raw predictions: class logits, bboxes, and confidence scores
    """

    def __init__(self, model, cfg):
        super().__init__()
        self.model = model.eval()
        self.converter = create_converter(
            cfg.model.name,
            model,
            cfg.model.anchor,
            cfg.task.data.image_size,
            device="cpu",
        )

    def forward(self, x):
        preds = self.model(x)
        heads = preds["Main"] if isinstance(preds, dict) else preds

        # Convert model output to bbox format (without NMS)
        prediction = self.converter(heads)
        pred_class, _, pred_bbox = prediction[:3]
        pred_conf = prediction[3] if len(prediction) == 4 else None

        # Output raw predictions for external NMS processing
        # pred_class: [B, num_anchors, num_classes] - class logits (before sigmoid)
        # pred_bbox: [B, num_anchors, 4] - bounding boxes in xyxy format
        # pred_conf: [B, num_anchors, 1] - objectness confidence (sigmoid applied) or None

        if pred_conf is not None:
            return pred_class, pred_bbox, pred_conf
        else:
            return pred_class, pred_bbox


def export_full_onnx():
    print("ğŸš€ ONNXå¤‰æ›ã‚’é–‹å§‹ (NMSè¾¼ã¿)...")

    try:
        # 1. è¨­å®šèª­ã¿è¾¼ã¿
        print("ğŸ“‹ è¨­å®šã‚’èª­ã¿è¾¼ã¿ä¸­...")
        with initialize(config_path="yolo/config", version_base=None):
            cfg = compose(
                config_name="config.yaml",
                overrides=[
                    "task=inference",
                    f"model={MODEL_NAME}",
                    f"dataset.class_num={NUM_CLASSES}",
                ],
            )
        print(f"âœ… è¨­å®šèª­ã¿è¾¼ã¿å®Œäº† (ãƒ¢ãƒ‡ãƒ«: {MODEL_NAME}, ã‚¯ãƒ©ã‚¹æ•°: {NUM_CLASSES})")
        print(f"   - ç”»åƒã‚µã‚¤ã‚º: {cfg.task.data.image_size}")
        print(
            f"   - NMSè¨­å®š: min_confidence={cfg.task.nms.min_confidence}, min_iou={cfg.task.nms.min_iou}"
        )

        # 2. ãƒ¢ãƒ‡ãƒ«ä½œæˆ
        print("ğŸ—ï¸ ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆä¸­...")
        model = create_model(cfg.model, class_num=NUM_CLASSES)
        print("âœ… ãƒ¢ãƒ‡ãƒ«ä½œæˆå®Œäº†")

        # 3. ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿
        print(f"ğŸ“¦ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿ä¸­: {CKPT_PATH}")
        ckpt = torch.load(CKPT_PATH, map_location="cpu")
        state_dict = ckpt["state_dict"]

        # Lightningå½¢å¼ã®ã‚­ãƒ¼åå¤‰æ› (model.model.* â†’ model.*)
        new_state_dict = {}
        for key, value in state_dict.items():
            if key.startswith("model."):
                new_key = key[6:]  # "model."ã‚’å‰Šé™¤
                new_state_dict[new_key] = value
            else:
                new_state_dict[key] = value

        # ãƒ¢ãƒ‡ãƒ«ã«é‡ã¿ã‚’èª­ã¿è¾¼ã¿
        missing_keys, unexpected_keys = model.load_state_dict(
            new_state_dict, strict=False
        )
        if missing_keys:
            print(f"âš ï¸ ä¸è¶³ã‚­ãƒ¼: {len(missing_keys)}å€‹")
        if unexpected_keys:
            print(f"âš ï¸ ä½™åˆ†ã‚­ãƒ¼: {len(unexpected_keys)}å€‹")
        print("âœ… ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿å®Œäº†")

        # 4. ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨ãƒ©ãƒƒãƒ‘ãƒ¼ä½œæˆ
        print("ğŸ”§ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨ãƒ©ãƒƒãƒ‘ãƒ¼ã‚’ä½œæˆä¸­...")
        wrapper = FullYoloExport(model, cfg).eval()

        # 5. ãƒ€ãƒŸãƒ¼å…¥åŠ›ä½œæˆ
        image_size = cfg.task.data.image_size
        dummy_input = torch.randn(1, 3, image_size[0], image_size[1])
        print(f"âœ… ãƒ€ãƒŸãƒ¼å…¥åŠ›ä½œæˆå®Œäº† (ã‚µã‚¤ã‚º: {dummy_input.shape})")

        # 6. ONNX Export
        print(f"ğŸ”„ ONNXå¤‰æ›ä¸­: {EXPORT_ONNX_FILE}")
        torch.onnx.export(
            wrapper,
            dummy_input,
            EXPORT_ONNX_FILE,
            opset_version=20,
            # dynamo=True,
            input_names=["input"],
            output_names=["output"],
            dynamic_axes={
                "input": {0: "batch"},
            },
            verbose=False,  # è©³ç´°ãƒ­ã‚°ã‚’éè¡¨ç¤º
        )

        print(f"ğŸ‰ ONNXå¤‰æ›å®Œäº†: {EXPORT_ONNX_FILE}")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback

        traceback.print_exc()


def export_raw_onnx():
    """Export ONNX without NMS for flexible post-processing"""
    print("ğŸš€ ONNXå¤‰æ›ã‚’é–‹å§‹ (NMSç„¡ã—)...")

    try:
        # 1. è¨­å®šèª­ã¿è¾¼ã¿
        print("ğŸ“‹ è¨­å®šã‚’èª­ã¿è¾¼ã¿ä¸­...")
        with initialize(config_path="yolo/config", version_base=None):
            cfg = compose(
                config_name="config.yaml",
                overrides=[
                    "task=inference",
                    f"model={MODEL_NAME}",
                    f"dataset.class_num={NUM_CLASSES}",
                ],
            )
        print(f"âœ… è¨­å®šèª­ã¿è¾¼ã¿å®Œäº† (ãƒ¢ãƒ‡ãƒ«: {MODEL_NAME}, ã‚¯ãƒ©ã‚¹æ•°: {NUM_CLASSES})")
        print(f"   - ç”»åƒã‚µã‚¤ã‚º: {cfg.task.data.image_size}")

        # 2. ãƒ¢ãƒ‡ãƒ«ä½œæˆ
        print("ğŸ—ï¸ ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆä¸­...")
        model = create_model(cfg.model, class_num=NUM_CLASSES)
        print("âœ… ãƒ¢ãƒ‡ãƒ«ä½œæˆå®Œäº†")

        # 3. ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿
        print(f"ğŸ“¦ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿ä¸­: {CKPT_PATH}")
        ckpt = torch.load(CKPT_PATH, map_location="cpu")
        state_dict = ckpt["state_dict"]

        # Lightningå½¢å¼ã®ã‚­ãƒ¼åå¤‰æ› (model.model.* â†’ model.*)
        new_state_dict = {}
        for key, value in state_dict.items():
            if key.startswith("model."):
                new_key = key[6:]  # "model."ã‚’å‰Šé™¤
                new_state_dict[new_key] = value
            else:
                new_state_dict[key] = value

        # ãƒ¢ãƒ‡ãƒ«ã«é‡ã¿ã‚’èª­ã¿è¾¼ã¿
        missing_keys, unexpected_keys = model.load_state_dict(
            new_state_dict, strict=False
        )
        if missing_keys:
            print(f"âš ï¸ ä¸è¶³ã‚­ãƒ¼: {len(missing_keys)}å€‹")
        if unexpected_keys:
            print(f"âš ï¸ ä½™åˆ†ã‚­ãƒ¼: {len(unexpected_keys)}å€‹")
        print("âœ… ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿å®Œäº†")

        # 4. ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨ãƒ©ãƒƒãƒ‘ãƒ¼ä½œæˆ (NMSç„¡ã—)
        print("ğŸ”§ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨ãƒ©ãƒƒãƒ‘ãƒ¼ã‚’ä½œæˆä¸­ (NMSç„¡ã—)...")
        wrapper = RawYoloExport(model, cfg).eval()

        # 5. ãƒ€ãƒŸãƒ¼å…¥åŠ›ä½œæˆ
        image_size = cfg.task.data.image_size
        dummy_input = torch.randn(1, 3, image_size[0], image_size[1])
        print(f"âœ… ãƒ€ãƒŸãƒ¼å…¥åŠ›ä½œæˆå®Œäº† (ã‚µã‚¤ã‚º: {dummy_input.shape})")

        # 6. å‡ºåŠ›ãƒ†ã‚¹ãƒˆ
        print("ğŸ§ª å‡ºåŠ›å½¢çŠ¶ãƒ†ã‚¹ãƒˆä¸­...")
        with torch.no_grad():
            outputs = wrapper(dummy_input)
            if isinstance(outputs, tuple):
                if len(outputs) == 3:
                    pred_class, pred_bbox, pred_conf = outputs
                    print(f"   - pred_class: {pred_class.shape} (ã‚¯ãƒ©ã‚¹ã‚¹ã‚³ã‚¢)")
                    print(f"   - pred_bbox: {pred_bbox.shape} (ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹)")
                    print(f"   - pred_conf: {pred_conf.shape} (ä¿¡é ¼åº¦)")
                    output_names = ["pred_class", "pred_bbox", "pred_conf"]
                else:
                    pred_class, pred_bbox = outputs
                    print(f"   - pred_class: {pred_class.shape} (ã‚¯ãƒ©ã‚¹ã‚¹ã‚³ã‚¢)")
                    print(f"   - pred_bbox: {pred_bbox.shape} (ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹)")
                    output_names = ["pred_class", "pred_bbox"]

        # 7. ONNX Export
        output_file = EXPORT_ONNX_FILE.replace(".onnx", "_raw.onnx")
        print(f"ğŸ”„ ONNXå¤‰æ›ä¸­: {output_file}")
        torch.onnx.export(
            wrapper,
            dummy_input,
            output_file,
            opset_version=20,
            input_names=["input"],
            output_names=output_names,
            dynamic_axes={
                "input": {0: "batch"},
                output_names[0]: {0: "batch"},
                output_names[1]: {0: "batch"},
            },
            verbose=False,
        )

        print(f"ğŸ‰ ONNXå¤‰æ›å®Œäº†: {output_file}")
        print("   - NMSå‡¦ç†ã¯æ¨è«–æ™‚ã«å¤–éƒ¨ã§å®Ÿè¡Œã—ã¦ãã ã•ã„")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="YOLOv9 ONNX Export")
    parser.add_argument(
        "--mode",
        choices=["full", "raw"],
        default="full",
        help="Export mode: 'full' (with NMS) or 'raw' (without NMS)",
    )
    args = parser.parse_args()

    if args.mode == "full":
        export_full_onnx()
    else:
        export_raw_onnx()
